{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Xception Model"
      ],
      "metadata": {
        "id": "8Xw_PSXS699v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "OSK_mWWq65iz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLHR3BHrG22v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "0cAlaCd-7clw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "  @staticmethod\n",
        "  def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "SNht9aUo7aP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessor"
      ],
      "metadata": {
        "id": "IdBoxJnQ8NIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "  @staticmethod\n",
        "  def preprocess_data(x_train, x_val, x_test):\n",
        "    x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "    x_val = x_val.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "    x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32') / 255.0\n",
        "    return x_train, x_val, x_test"
      ],
      "metadata": {
        "id": "gKrzVwue8L4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Builder"
      ],
      "metadata": {
        "id": "juE9r-Zb81tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBuilder:\n",
        "  @staticmethod\n",
        "  def build_model(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Entry Flow\n",
        "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=input_shape, padding='same'))\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
        "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Middle Flow\n",
        "    for _ in range(8):\n",
        "      model.add(XceptionBlock(128))\n",
        "\n",
        "    # Exit Flow\n",
        "    model.add(layers.SeparableConv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "class XceptionBlock(layers.Layer):\n",
        "  def __init__(self, filters):\n",
        "    super(XceptionBlock, self).__init__()\n",
        "\n",
        "    self.sep_conv1 = layers.SeparableConv2D(filters, (3, 3), activation='relu', padding='same')\n",
        "    self.sep_conv2 = layers.SeparableConv2D(filters, (3, 3), activation='relu', padding='same')\n",
        "    self.sep_conv3 = layers.SeparableConv2D(filters, (3, 3), activation='relu', padding='same')\n",
        "    self.add_residual = layers.Add()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.sep_conv1(inputs)\n",
        "    x = self.sep_conv2(x)\n",
        "    x = self.sep_conv3(x)\n",
        "    return self.add_residual([inputs, x])"
      ],
      "metadata": {
        "id": "jxzsiw8K81OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer"
      ],
      "metadata": {
        "id": "VKcycRfBABgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "  def __init__(self, model, optimizer, loss_function, metrics):\n",
        "    self.model = model\n",
        "    self.model.compile(optimizer = optimizer, loss=loss_function, metrics=metrics)\n",
        "\n",
        "  def train_model(self, x_train, y_train, x_val, y_val, epochs, batch_size):\n",
        "    history = self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val), verbose=2)\n",
        "    return history"
      ],
      "metadata": {
        "id": "eP5aUalAAAfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  x_train, y_train, x_val, y_val, x_test, y_test = DataLoader.load_data()\n",
        "  x_train, x_val, x_test = DataPreprocessor.preprocess_data(x_train, x_val, x_test)\n",
        "\n",
        "  input_shape = x_train.shape[1:]\n",
        "  num_classes = 10\n",
        "\n",
        "  model = ModelBuilder.build_model(input_shape, num_classes)\n",
        "\n",
        "  optimizer = 'adam'\n",
        "  loss_function = 'sparse_categorical_crossentropy'\n",
        "  metrics = ['accuracy']\n",
        "\n",
        "  trainer = Trainer(model, optimizer, loss_function, metrics)\n",
        "\n",
        "  epochs = 5\n",
        "  batch_size = 32\n",
        "\n",
        "  history = trainer.train_model(x_train, y_train, x_val, y_val, epochs, batch_size)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "  print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "gaE2f-n8A2ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx_RVWGhCP4-",
        "outputId": "231dbbe1-dd2c-4b0e-cc58-b5a11b7d0a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 - 104s - loss: 0.4086 - accuracy: 0.8641 - val_loss: 0.1203 - val_accuracy: 0.9638 - 104s/epoch - 69ms/step\n",
            "Epoch 2/5\n",
            "1500/1500 - 94s - loss: 0.1035 - accuracy: 0.9688 - val_loss: 0.1069 - val_accuracy: 0.9672 - 94s/epoch - 63ms/step\n",
            "Epoch 3/5\n",
            "1500/1500 - 89s - loss: 0.0707 - accuracy: 0.9782 - val_loss: 0.0636 - val_accuracy: 0.9814 - 89s/epoch - 60ms/step\n",
            "Epoch 4/5\n",
            "1500/1500 - 90s - loss: 0.0552 - accuracy: 0.9824 - val_loss: 0.0656 - val_accuracy: 0.9810 - 90s/epoch - 60ms/step\n",
            "Epoch 5/5\n",
            "1500/1500 - 90s - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.0889 - val_accuracy: 0.9724 - 90s/epoch - 60ms/step\n",
            "313/313 - 7s - loss: 0.0825 - accuracy: 0.9738 - 7s/epoch - 21ms/step\n",
            "Test Accuracy: 97.38%\n"
          ]
        }
      ]
    }
  ]
}